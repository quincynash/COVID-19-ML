#!/usr/bin/env python3
# -*- coding: utf-8 -*-


"""
This program trains and saves a machine learning model that detects COVID-19
with Image Classification through tensorflow
"""


import os
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras.losses import SparseCategoricalCrossentropy
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout
from keras.optimizers import Adam
from keras.utils import Sequence

from sklearn.metrics import classification_report


__author__ = "Quincy Nash"
__copyright__ = "Copyright January 16, 2021"
__credits__ = ["Rajat Garg", "Tanishq Gautam", "NIH Clinical Center"]
__license__ = "GPL"
__version__ = "1.0.1"
__maintainer__ = "Quincy Nash"
__email__ = "quincy.nash@icloud.com"
__status__ = "Production"


class Generator(Sequence):
    def __init__(self, home_dir, image_filenames, labels, size):
        self.home_dir = home_dir
        self.image_filenames = image_filenames
        self.labels = labels
        self.batch_size = size

    def __len__(self):
        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)

    def __getitem__(self, idx):
        batch_x = self.image_filenames[idx * self.batch_size: (idx + 1) * self.batch_size]
        batch_y = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]

        return np.reshape([np.array(cv.imread(os.path.join(self.home_dir, types[batch_y[
            np.where(batch_x == file_name)[0][0]]], str(file_name)), cv.IMREAD_GRAYSCALE)) / 255
                           for file_name in batch_x], (self.batch_size, img_size, img_size, 1)), np.array(batch_y)


def file_names_and_labels(data_dir):
    covid_names = [f for f in os.listdir(os.path.join(data_dir, types[0])) if not f.startswith('.')]
    other_names = [f for f in os.listdir(os.path.join(data_dir, types[1])) if not f.startswith('.')]

    all_names = np.concatenate((covid_names, other_names))
    labels = np.array([0 for _ in covid_names] + [1 for _ in other_names])

    length = len(all_names)
    all_names = all_names[:length - (length % batch_size)]

    shuffler = np.random.permutation(len(all_names))
    all_names = all_names[shuffler]
    labels = labels[shuffler]

    return all_names, labels


print("Libraries successfully loaded")

# Constants
root_dir = "/Users/quincynash/Desktop/8th Grade Science Fair/Science Fair Images 50000"
save_location = "/Users/quincynash/Desktop/8th Grade Science Fair/Trained Model"  # Directory doesn't need to exist yet
types = ["COVID-19", "Other"]  # Labels for data
img_size = 600
batch_size = 25
epochs = 10

# Load file names and labels of images
train_files, train_labels = file_names_and_labels(os.path.join(root_dir, "Train"))
val_files, val_labels = file_names_and_labels(os.path.join(root_dir, "Validation"))
test_files, test_labels = file_names_and_labels(os.path.join(root_dir, "Test"))
training_generator = Generator(os.path.join(root_dir, "Train"), train_files, train_labels, batch_size)
validation_generator = Generator(os.path.join(root_dir, "Validation"), val_files, val_labels, batch_size)
testing_generator = Generator(os.path.join(root_dir, "Test"), test_files, test_labels, batch_size)
print("Image file names successfully loaded")

# Create Convolutional Neural Network (CNN)
model = Sequential([
    Conv2D(32, 3, padding="same", activation="relu", input_shape=(img_size, img_size, 1)),  # Convolution Layer
    MaxPool2D(),  # Downsample image to lower resolution
    Conv2D(32, 3, padding="same", activation="relu"),  # Convolution Layer
    MaxPool2D(),  # Downsample image to lower resolution
    Conv2D(64, 3, padding="same", activation="relu"),  # Convolution Layer
    MaxPool2D(),  # Downsample image to lower resolution
    Dropout(0.4),  # 40% chance node will be dropped out - leads to better training
    Flatten(),  # Flatten model shape
    Dense(128, activation="relu"),  # Neural Network Layer
    Dense(2, activation="softmax")  # Neural Network Layer
])

model.summary()

# Compile the model
opt = Adam(lr=0.00001)
model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
print("Model successfully created and compiled - Beginning training")

# Train the model
history = model.fit(
    training_generator,
    batch_size=batch_size,
    epochs=epochs,
    steps_per_epoch=len(train_files) // batch_size,
    validation_data=validation_generator,
    validation_steps=len(val_files) // batch_size,
    shuffle=False)

# Save model to given location
model.save(save_location)

# Make predictions on the accuracy of the model
predictions = np.argmax(model.predict(testing_generator), axis=-1)
print("\n" + classification_report(test_labels, predictions, target_names=types, zero_division=False))

# Create graphs showing the accuracy and loss of the model
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(loss))

plt.figure(num='COVID-19 Detection - Machine Learning Model', figsize=(15, 15))
plt.subplot(2, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
